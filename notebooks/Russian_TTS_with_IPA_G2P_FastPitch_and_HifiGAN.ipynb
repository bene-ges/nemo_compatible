{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t_xtPhVAdKhP"
      },
      "source": [
        "Install NeMo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKqBMpNuEMVL"
      },
      "outputs": [],
      "source": [
        "# Install NeMo library. If you are running locally (rather than on Google Colab), comment out the below lines\n",
        "# and instead follow the instructions at https://github.com/NVIDIA/NeMo#Installation\n",
        "GITHUB_ACCOUNT = \"NVIDIA\"\n",
        "BRANCH = \"main\"\n",
        "!python -m pip install git+https://github.com/{GITHUB_ACCOUNT}/NeMo.git@{BRANCH}#egg=nemo_toolkit[all]\n",
        "\n",
        "# Download local version of NeMo scripts. If you are running locally and want to use your own local NeMo code,\n",
        "# comment out the below lines and set NEMO_DIR to your local path.\n",
        "NEMO_DIR = 'nemo'\n",
        "!git clone -b {BRANCH} https://github.com/{GITHUB_ACCOUNT}/NeMo.git $NEMO_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XluZUtgV09N"
      },
      "source": [
        "Make imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHuyhJazErbe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import IPython.display as ipd\n",
        "import re\n",
        "import soundfile as sf\n",
        "from matplotlib.pyplot import imshow\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from nemo.collections.tts.models import FastPitchModel\n",
        "from nemo.collections.tts.models import HifiGanModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9MMFx0_V3gW"
      },
      "source": [
        "Define file names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfq3upYnJcpE"
      },
      "outputs": [],
      "source": [
        "INPUT_TEXT = \"input_text.txt\"\n",
        "INPUT_FOR_G2P = \"input_for_g2p.txt\"\n",
        "OUTPUT_OF_G2P = \"output_of_g2p.txt\"\n",
        "INPUT_TEXT_PHONEMES = \"input_text_phonemes.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB0MFkCmWBmn"
      },
      "source": [
        "Create file with some input text.\n",
        "Note that text normalization (conversion of digits to words etc.) is **not** included in this pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jQF1F3OFYri"
      },
      "outputs": [],
      "source": [
        "!echo \"(Я представляю себе вашу ироническую улыбку. Тем не менее – буквально два слова.) Как известно, мир несовершенен.\" > {INPUT_TEXT}\n",
        "!echo \"Устоями общества являются корыстолюбие, страх и продажность.\" >> {INPUT_TEXT}\n",
        "!echo \"Конфликт мечты с действительностью не утихает тысячелетиями.\" >> {INPUT_TEXT}\n",
        "!echo \"Вместо желаемой гармонии на земле царят хаос и беспорядок.\" >> {INPUT_TEXT}\n",
        "!echo \"Более того, нечто подобное мы обнаружили в собственной душе.\" >> {INPUT_TEXT}\n",
        "!echo \"Мы жаждем совершенства, а вокруг торжествует пошлость. Как в этой ситуации поступает деятель, революционер?\" >> {INPUT_TEXT}\n",
        "!echo \"Революционер делает попытки установить мировую гармонию.\" >> {INPUT_TEXT}\n",
        "!echo \"Он начинает преобразовывать жизнь, достигая иногда курьезных мичуринских результатов.\" >> {INPUT_TEXT}\n",
        "!echo \"Допустим, выводит морковь, совершенно неотличимую от картофеля. В общем, создает новую человеческую породу.\" >> {INPUT_TEXT}\n",
        "!echo \"Известно, чем это кончается… Что в этой ситуации предпринимает моралист? Он тоже пытается достичь гармонии.\" >> {INPUT_TEXT}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imZla8ZpWzmZ"
      },
      "source": [
        "Some helper preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3nGXsYTI6GW"
      },
      "outputs": [],
      "source": [
        "def clean_russian_g2p_trascription(text: str) -> str:\n",
        "    result = text\n",
        "    result = result.replace(\"<DELETE>\", \" \").replace(\"+\", \"\").replace(\"~\", \"\")\n",
        "    result = result.replace(\"ʑ\", \"ɕ:\").replace(\"ɣ\", \"x\")\n",
        "    result = result.replace(\":\", \"ː\").replace(\"'\", \"`\")\n",
        "    result = \"\".join(result.split())\n",
        "    result = result.replace(\"_\", \" \")\n",
        "    return result\n",
        "\n",
        "\n",
        "def clean_russian_text_for_tts(text: str) -> str:\n",
        "    result = text\n",
        "    result = result.replace(\"+\", \"\")  # remove stress\n",
        "    result = result.casefold()  # lowercase\n",
        "    result = result.replace(\"ё\", \"е\")\n",
        "    result = result.replace(\"\\u2011\", \"-\")  # non-breaking hyphen\n",
        "    result = result.replace(\"\\u2014\", \"-\")  # em dash\n",
        "    result = result.replace(\"\\u2026\", \".\")  # horizontal ellipsis\n",
        "    result = result.replace(\"\\u00ab\", \"\\\"\")  # LEFT-POINTING DOUBLE ANGLE QUOTATION MARK\n",
        "    result = result.replace(\"\\u00bb\", \"\\\"\")  # RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK\n",
        "    result = result.replace(\"\\u2019\", \"'\")  # ’ Right Single Quotation Mark\n",
        "    result = result.replace(\"\\u201c\", \"\\\"\")  # “ Left Double Quotation Mark\n",
        "    result = result.replace(\"\\u201d\", \"\\\"\")  # ” Right Double Quotation Mark\n",
        "    result = result.replace(\"\\u201e\", \"\\\"\")  # „ Double Low-9 Quotation Mark\n",
        "    result = result.replace(\"\\u201f\", \"\\\"\")  # ‟ Double High-reversed-9 Quotation Mark\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju6jWFQUW8Ae"
      },
      "source": [
        "Take all unique words from the input text and prepare them to feed to G2P model.\n",
        "Note that G2P model works with separate words and does not take context into account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tOckIa1JNPs"
      },
      "outputs": [],
      "source": [
        "all_words = set()\n",
        "with open(INPUT_TEXT, \"r\", encoding=\"utf-8\") as inp:\n",
        "    for line in inp:\n",
        "        text = line.strip()\n",
        "        words = re.compile('\\w+').findall(text)\n",
        "        for w in words:\n",
        "            all_words.add(clean_russian_text_for_tts(w))            \n",
        "\n",
        "with open(INPUT_FOR_G2P, \"w\", encoding=\"utf-8\") as out:\n",
        "    for w in all_words:\n",
        "        out.write(\" \".join(list(w)) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kO6QZmCbKRd-"
      },
      "outputs": [],
      "source": [
        "!head {INPUT_FOR_G2P}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vM1tso1XnvF"
      },
      "source": [
        "Clone [G2P model](https://huggingface.co/bene-ges/ru_g2p_ipa_bert_large) from HuggingFace.\n",
        "If cloning doesn't work try `git lfs install`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjgXGRtzMqpl"
      },
      "outputs": [],
      "source": [
        "!git clone https://huggingface.co/bene-ges/ru_g2p_ipa_bert_large"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtiNwKhOYKrP"
      },
      "source": [
        "Run G2P inference on the words that we prepared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00OyJiTKMX23"
      },
      "outputs": [],
      "source": [
        "!python {NEMO_DIR}/examples/nlp/text_normalization_as_tagging/normalization_as_tagging_infer.py \\\n",
        "  pretrained_model=ru_g2p_ipa_bert_large/ru_g2p.nemo \\\n",
        "  inference.from_file={INPUT_FOR_G2P} \\\n",
        "  inference.out_file={OUTPUT_OF_G2P} \\\n",
        "  model.max_sequence_len=512 \\\n",
        "  inference.batch_size=128 \\\n",
        "  lang=ru\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uu9rgtKcP2H-"
      },
      "outputs": [],
      "source": [
        "!head {OUTPUT_OF_G2P}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khu8G5qiQG4e"
      },
      "source": [
        "Preprocess input text for TTS using G2P results and vocabularies of known transcriptions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1M5lytAQFlu"
      },
      "outputs": [],
      "source": [
        "# heteronyms are words with ambiguous transcription, we will leave them as plain text\n",
        "heteronyms = set()\n",
        "with open(\"ru_g2p_ipa_bert_large/heteronyms.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        inp = line.strip()\n",
        "        heteronyms.add(inp)\n",
        "\n",
        "g2p_vocab = {}\n",
        "# first read transcriptions from our g2p prediction\n",
        "with open(OUTPUT_OF_G2P, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            _, inp, transcription, _, _ = line.strip().split(\"\\t\")\n",
        "        except:\n",
        "            print(\"cannot read line: \" + line)\n",
        "            continue\n",
        "        inp = inp.replace(\" \", \"\")\n",
        "        g2p_vocab[inp] = clean_russian_g2p_trascription(transcription)\n",
        "\n",
        "# then override known transcriptions using vocabulary\n",
        "with open(\"ru_g2p_ipa_bert_large/g2p_correct_vocab.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        # Example input: ледок \\t lʲɪd`ok\n",
        "        inp, transcription = line.strip().split(\"\\t\")\n",
        "        g2p_vocab[inp] = transcription\n",
        "\n",
        "out = open(INPUT_TEXT_PHONEMES, \"w\", encoding=\"utf-8\")\n",
        "\n",
        "with open(INPUT_TEXT, \"r\", encoding=\"utf-8\") as inp:\n",
        "    for line in inp:\n",
        "        text = line.strip()\n",
        "        text = clean_russian_text_for_tts(text)\n",
        "        phonemized_text = \"\"\n",
        "        m = re.search(r\"[\\w\\-]+\", text)\n",
        "        while m is not None:\n",
        "            begin = m.start()\n",
        "            end = m.end()\n",
        "            phonemized_text += text[0:begin]\n",
        "            w = text[begin:end]\n",
        "            if w in heteronyms:\n",
        "                phonemized_text += w\n",
        "            elif w in g2p_vocab:\n",
        "                phonemized_text += clean_russian_g2p_trascription(g2p_vocab[w])\n",
        "            else:  # shouldn't go here as all words are expected to pass through g2p\n",
        "                phonemized_text += w\n",
        "\n",
        "            if end >= len(text):\n",
        "                break\n",
        "            text = text[end:]\n",
        "            end = 0\n",
        "            m = re.search(r\"[\\w\\-]+\", text)\n",
        "        if end < len(text):\n",
        "            phonemized_text += text[end:]\n",
        "        \n",
        "        out.write(phonemized_text + \"\\n\")\n",
        "\n",
        "out.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfqPBe1oYsX_"
      },
      "source": [
        "Look at the final TTS input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wpxmChtTFnn"
      },
      "outputs": [],
      "source": [
        "!head {INPUT_TEXT_PHONEMES} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF2PrP7VZKb-"
      },
      "source": [
        "Run TTS. The resulting wav files will be saved to working directory and also displayed in the output cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMB7wqKOFLbP"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = \"cuda\"\n",
        "else:\n",
        "  device = \"cpu\"\n",
        "\n",
        "# Load FastPitch\n",
        "spectrogram_generator = FastPitchModel.from_pretrained(\"bene-ges/tts_ru_ipa_fastpitch_ruslan\").eval().to(device)\n",
        "# Load vocoder\n",
        "vocoder = HifiGanModel.from_pretrained(model_name=\"bene-ges/tts_ru_hifigan_ruslan\").eval().to(device)\n",
        "\n",
        "i = 0\n",
        "with open(INPUT_TEXT_PHONEMES, \"r\", encoding=\"utf-8\") as inp:\n",
        "    for line in inp:\n",
        "        text = line.strip()\n",
        "        parsed = spectrogram_generator.parse(text)\n",
        "        spectrogram = spectrogram_generator.generate_spectrogram(tokens=parsed)\n",
        "        audio = vocoder.convert_spectrogram_to_audio(spec=spectrogram)\n",
        "\n",
        "        # Note that vocoder return a batch of audio. In this example, we just take the first and only sample.\n",
        "        filename = str(i) + \".wav\"\n",
        "        sf.write(filename, audio.to('cpu').detach().numpy()[0], 22050)\n",
        "        i += 1\n",
        "\n",
        "        # display\n",
        "        print(f'\"{text}\"\\n')\n",
        "        ipd.display(ipd.Audio(audio.to('cpu').detach(), rate=22050))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
